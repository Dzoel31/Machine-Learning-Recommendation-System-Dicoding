# -*- coding: utf-8 -*-
"""submission_recommender_user_based.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tROdTT9iyI_ZKZN5k8EC3C-guHBuU6yD

# Final Submission: Rekomendasi Wisata di 5 Kota di Indonesia

- Name:  Dzulfikri Adjmal
- Email: dzulfikriadjmal@gmail.com
- ID Dicoding: dzulfikriadjmal

# Mengimport library yang dibutuhkan
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import root_mean_squared_error
from sklearn.metrics.pairwise import cosine_similarity
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory

import tensorflow as tf
from tensorflow.keras import layers
from tensorflow import keras

from pathlib import Path

"""## Data Assessing

Memuat semua data destinasi wisata
"""

df_user = pd.read_csv('./dataset/indonesia-tourism-destination/user.csv')
df_destination = pd.read_csv('./dataset/indonesia-tourism-destination/tourism_with_id.csv')
df_rating = pd.read_csv('./dataset/indonesia-tourism-destination/tourism_rating.csv')
df_package = pd.read_csv('./dataset/indonesia-tourism-destination/package_tourism.csv')

"""Melihat deskripsi data user"""

df_user.info()

"""Melihat deskripsi data destinasi"""

df_destination.info()

"""Melihat deskripsi data rating"""

df_rating.info()

"""Melihat deskripsi data paket wisata"""

df_package.info()

"""Melihat sample data user menggunakan `head()`"""

df_user.head()

"""Melihat sample data destinasi menggunakan `head()`"""

df_destination.head()

"""Melihat sample data rating menggunakan `head()`"""

df_rating.head()

"""Melihat sample data paket wisata menggunakan `head()`"""

df_package.head()

"""Mengecek missing value pada data user"""

df_user.isna().sum()

"""Mengecek missing value pada data destinasi"""

df_destination.isna().sum()

"""Mengecek missing value pada data rating"""

df_rating.isna().sum()

"""Mengecek missing value pada data paket wisata"""

df_package.isna().sum()

"""## Preprocessing Data

Mengecek nilai pada kolom rating
"""

print(f"Nilai rating (user): {df_rating['Place_Ratings'].unique()}")
print(f"Nilai rating (destinasi): {df_destination['Rating'].unique()}")

"""Melihat ukuran data"""

print(f"Banyak rating: {len(df_rating)}")
print(f"Banyak user: {len(df_user)}")
print(f"Banyak destinasi: {len(df_destination)}")

"""melihat data kategori wisata"""

df_destination['Category'].unique()

"""Menghapus kolom yang tidak diperlukan"""

df_destination.drop([
    "Time_Minutes",
    "Coordinate",
    "Lat",
    "Long",
    "Unnamed: 11",
    "Unnamed: 12"
], axis=1, inplace=True)
df_destination

"""Menggabungkan data rating dengan data user"""

data_destinasi = df_destination.copy()
data_rating_user = df_rating.copy()

data_rekomendasi = pd.merge(data_rating_user, df_user, on='User_Id')
data_rekomendasi.head()

"""Menggabungkan data dengan data destinasi"""

data_rekomendasi = pd.merge(data_rekomendasi, data_destinasi, on='Place_Id')
data_rekomendasi.head()

"""Mengubah nama kolom rating agar lebih mudah dibedakan antara rating dari user dengan rating rata-rata"""

data_rekomendasi.rename(columns={
    "Place_Ratings": "Rating_User",
    "Rating": "Rating Destination"
}, inplace=True)
data_rekomendasi.head()

"""Mengecek apakah terdapat data yang duplikat"""

data_rekomendasi.duplicated().sum()

"""Menghapus data yang duplikat"""

data_rekomendasi.drop_duplicates(inplace=True)
data_rekomendasi.shape

"""## Exploratory Data Analysis

Melihat jumlah kategori wisata di setiap kota
"""

destination_count = data_rekomendasi.groupby(by=['City', 'Category']).agg({
    'Place_Id': 'count'
}).reset_index().rename(columns={"Place_Id": "Jumlah Destinasi"})

destination_count_plot = px.bar(
    destination_count,
    x='City',
    y='Jumlah Destinasi',
    color='Category',
    barmode='group',
    text='Jumlah Destinasi',
    title='Jumlah Destinasi Wisata Berdasarkan Kota dan Kategori'
)
destination_count_plot.show()

"""Tempat wisata dengan rating tertinggi di setiap kota"""

top_destination = data_rekomendasi.loc[data_rekomendasi.groupby('City')['Rating Destination'].idxmax()][['City', 'Place_Name', 'Rating Destination']]

top_destination_plot = px.bar(
    top_destination,
    x='Rating Destination',
    y='City',
    text='Rating Destination',
    color='Place_Name',
    orientation='h',
    title='Destinasi Wisata Terbaik Berdasarkan Kota'
)
top_destination_plot.show()

"""## Content Based Filtering - Cosine Similarity

Menyalin data rekomendasi agar tidak merusak data asli
"""

rekomen_cosine = data_rekomendasi.copy()
rekomen_cosine.head()

"""Membuat tag pada data destinasi yang terdiri dari kategori dan nama kota."""

place_name = rekomen_cosine['Place_Name'].to_list()
place_category = rekomen_cosine['Category'].to_list()
place_city = rekomen_cosine['City'].to_list()

place_tag = [f"{place_category[i]}, {place_city[i]}" for i in range(len(place_name))]
place_tag[:5]

"""Melihat jumlah tag"""

print(f"Jumlah tag: {len(place_tag)}")
print(f"Tag yang tersedia: {len(set(place_tag))}")
print(f"Tag: {set(place_tag)}")

"""Membuat dataframe yang berisi destinasi id, nama destinasi, dan tag"""

data_rekomen_cosine = pd.DataFrame({
    "destination_id": rekomen_cosine['Place_Id'],
    "destination_name": place_name,
    "destination_tag": place_tag
})

data_rekomen_cosine.dropna(subset=['destination_tag'], inplace=True)
data_rekomen_cosine.head()

"""Mengecek data duplikat pada data rekomendasi"""

data_rekomen_cosine.duplicated().sum()

"""Menghapus data duplikat pada data rekomendasi"""

data_rekomen_cosine.drop_duplicates(inplace=True)
data_rekomen_cosine.duplicated().sum()

"""Mengubah kumpulan tag destinasi menjadi representasi numerik (vektor) menggunakan teknik TF-IDF"""

tfidf = TfidfVectorizer()

tfidf.fit(data_rekomen_cosine['destination_tag'])
tfidf.get_feature_names_out()

"""Mengubah tag destinasi menjadi matriks TF-IDF, yang merupakan representasi numerik dari dokumen (destinasi) dan kata-kata (tag)"""

tfidf_matrix = tfidf.fit_transform(data_rekomen_cosine['destination_tag'])
tfidf_matrix.shape

"""Mengubah matriks TF-IDF yang awalnya disimpan dalam format sparse menjadi format dense"""

tfidf_matrix.todense()

"""Menampilkan sampel acak dari 5 destinasi dan 15 tag destinasi, dengan nilai-nilai TF-IDF yang menunjukkan relevansi setiap tag terhadap masing-masing destinasi."""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf.get_feature_names_out(),
    index=data_rekomen_cosine['destination_name']
).sample(15, axis=1).sample(5, axis=0)

"""Menghitung cosine similarity antara setiap pasangan destinasi berdasarkan representasi TF-IDF"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Mengubah matriks cosine similarity menjadi DataFrame Pandas, memberikan nama destinasi sebagai indeks dan kolom, lalu mencetak ukuran DataFrame dan menampilkan 5 baris teratas"""

cosine_sim_data = pd.DataFrame(
    cosine_sim,
    index=data_rekomen_cosine['destination_name'],
    columns=data_rekomen_cosine['destination_name'],
)
print(f"Ukuran data: {cosine_sim_data.shape}")
cosine_sim_data.head()

"""Membuat fungsi rekomendasi destinasi berdasarkan nama destinasi yang diberikan dan menampilkan N destinasi yang paling mirip"""

def destination_recommender(
    destination_name,
    data_similarity=cosine_sim_data,
    items=data_rekomen_cosine[["destination_name", "destination_tag"]],
    topn=5,
):
    index = data_similarity.loc[:, destination_name].to_numpy().argpartition(range(-1, -topn, -1))
    closest = data_similarity.columns[index[-1 : -(topn + 2) : -1]]
    closest = closest.drop(destination_name, errors="ignore")
    return pd.DataFrame(closest).merge(items).head(topn)

"""Mengambil salah satu nama destinasi secara acak yang akan digunakan untuk melihat rekomendasi destinasi yang mirip"""

data_rekomen_cosine[data_rekomen_cosine['destination_name'].eq('Museum Nasional')]
random_destination = data_rekomen_cosine.sample(1).iloc[0]
print(f"Destination Name: {random_destination['destination_name']}")
print(f"Destination Tag: {random_destination['destination_tag']}")

"""Melihat 10 hasil rekomendasi berdasarkan cosine similarity"""

destination_recommender(random_destination['destination_name'], topn=10)

"""## Collaborative Filtering

Melakukan encoding pada data user id
"""

user_id = df_rating["User_Id"].unique().tolist()
print("Daftar user_id: ", user_id)

user_id_to_encoded = {x: i for i, x in enumerate(user_id)}
print("Encoded user_id: ", user_id_to_encoded)

user_encoded_to_user = {i: x for i, x in enumerate(user_id)}
print("Encoded Angka ke user_id: ", user_encoded_to_user)

"""Melakukan encoding pada data place id"""

destination_id = df_rating["Place_Id"].unique().tolist()
print("Daftar destination_id: ", destination_id)

destination_id_to_encoded = {x: i for i, x in enumerate(destination_id)}
print("Encoded destination_id: ", destination_id_to_encoded)

anime_encoded_to_anime = {i: x for i, x in enumerate(destination_id)}
print("Encoded Angka ke destination_id: ", anime_encoded_to_anime)

"""Setelah di encoding, data di mapping dengan data user id dan place id"""

df_rating["user"] = df_rating["User_Id"].map(user_id_to_encoded)

df_rating["destination"] = df_rating["Place_Id"].map(destination_id_to_encoded)

"""Melihat jumlah data yang sudah diencode dan melihat nilai rating."""

num_user = len(user_id_to_encoded)
print("Number of User: ", num_user)

num_destination = len(destination_id_to_encoded)
print("Number of Movie: ", num_destination)

df_rating["Place_Ratings"] = df_rating["Place_Ratings"].values.astype(np.float32)

min_rating = min(df_rating["Place_Ratings"])
print("Min Place Ratings: ", min_rating)

max_rating = max(df_rating["Place_Ratings"])
print("Max Place Ratings: ", max_rating)

data_ratings = df_rating.sample(frac=1, random_state=42)
data_ratings.head()

"""Membagi dataset dengan proporsi 80:20."""

x = data_ratings[["user", "destination"]].values
y = data_ratings["Place_Ratings"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

train_indices = int(0.8 * data_ratings.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:],
)

print("x_train.shape: ", x_train.shape)
print("y_train.shape: ", y_train.shape)

"""Membangun arsitektur model collaborative filtering RecommenderNet dengan menggunakan TensorFlow"""

class RecommenderNet(tf.keras.Model):
    def __init__(self, num_user, num_destination, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_user = num_user
        self.num_destination = num_destination
        self.embedding_size = embedding_size
        self.user_embedding = layers.Embedding(
            num_user,
            embedding_size,
            embeddings_initializer="he_normal",
            embeddings_regularizer=keras.regularizers.l2(1e-6),
        )
        self.user_bias = layers.Embedding(num_user, 1)
        self.destination_embedding = layers.Embedding(
            num_destination,
            embedding_size,
            embeddings_initializer="he_normal",
            embeddings_regularizer=keras.regularizers.l2(1e-6),
        )
        self.destination_bias = layers.Embedding(num_destination, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        destination_vector = self.destination_embedding(inputs[:, 1])
        destination_bias = self.destination_bias(inputs[:, 1])

        dot_user_destination = tf.tensordot(user_vector, destination_vector, 2)

        x = dot_user_destination + user_bias + destination_bias

        return tf.nn.sigmoid(x)

"""membuat model RecommenderNet dengan loss BinaryCrossentropy, optimizer Adam, dan metrics RootMeanSquaredError"""

model = RecommenderNet(num_user, num_destination, 40)

# model compile
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()],
)

"""Melatih model menggunakan data yang sudah dibagi dan sebanyak 20 epoch"""

history = model.fit(
    x=x_train, y=y_train, epochs=20, validation_data=(x_val, y_val)
)

"""Melakukan visualisasi performa model berdasarkan nilai RMSE"""

plt.plot(history.history["root_mean_squared_error"])
plt.plot(history.history["val_root_mean_squared_error"])
plt.title("model_metrics")
plt.ylabel("root_mean_squared_error")
plt.xlabel("epoch")
plt.legend(["train", "test"], loc="upper left")
plt.show()

"""Nilai RMSE pada datta train dan data test"""

# Predict using the model
y_train_pred = model.predict(x_train)
y_pred = model.predict(x_val)


# Calculate RMSE Train and Val using Sklearn
train_rmse = root_mean_squared_error(y_train, y_train_pred)
val_rmse = root_mean_squared_error(y_val, y_pred)

print(f"Train RMSE: {train_rmse}")
print(f"Val RMSE: {val_rmse}")

"""Mempersiapkan data yang akan digunakan dalam sistem rekomendasi. Data ini akan menjadi input untuk algoritma rekomendasi yang akan memberikan saran destinasi baru kepada pengguna berdasarkan preferensi mereka."""

ratings = pd.read_csv("./dataset/indonesia-tourism-destination/tourism_rating.csv")
data_destination = df_destination[["Place_Id", "Place_Name", "Category"]]

user_id = ratings["User_Id"].sample(1).iloc[0]
destination_reviewed = ratings[ratings["User_Id"] == user_id]

destination_not_reviewed = data_destination[
    ~data_destination["Place_Id"].isin(destination_reviewed["Place_Id"].values)
]["Place_Id"]
destination_not_reviewed = list(
    set(destination_not_reviewed).intersection(set(destination_id_to_encoded.keys()))
)

destination_not_reviewed = [
    [destination_id_to_encoded.get(x)] for x in destination_not_reviewed
]
user_id_encoder = user_id_to_encoded.get(user_id)
user_destination_array = np.hstack(
    ([[user_id_encoder]] * len(destination_not_reviewed), destination_not_reviewed)
)

"""Melihat hasil rekomendasi model collaborative filtering dari satu user yang ditentukan secara acak"""

from prettytable import PrettyTable

result_rating = model.predict(user_destination_array).flatten()

top_ratings_indices = result_rating.argsort()[-10:][::-1]
destination_id = [
    anime_encoded_to_anime.get(destination_not_reviewed[x][0]) for x in top_ratings_indices
]

print("Rekomendasi destinasi untuk user_id: ", user_id)
print("===" * 9)
print("Destinasi yang direview: ")
print("===" * 9)

top_five_destination_reviewed = (
    destination_reviewed.sort_values(by="Place_Ratings", ascending=False)
    .head(10)
    .Place_Id.values
)

destination_df = df_destination[df_destination["Place_Id"].isin(top_five_destination_reviewed)]
table_reviewed = PrettyTable()
table_reviewed.field_names = ["Nama", "Kategori", "Rating"]
for index, row in destination_df.iterrows():
    table_reviewed.add_row([row['Place_Name'], row['Category'], row['Rating']])
print(table_reviewed)

print("Rekomendasi destinasi: ")

destination_df = df_destination[df_destination["Place_Id"].isin(destination_id)]
table_recommended = PrettyTable()
table_recommended.field_names = ["Nama", "Kategori", "Rating"]
for index, row in destination_df.iterrows():
    table_recommended.add_row([row['Place_Name'], row['Category'], row['Rating']])
print(table_recommended)